[2023-01-24 14:38:01][all_train.py][line:50][INFO] =============== DATA LOADING =============
[2023-01-24 14:38:01][dataset.py][line:124][INFO] DATA LOADING...
[2023-01-24 14:38:01][dataset.py][line:125][INFO] DATASET: toxic
[2023-01-24 14:38:01][dataset.py][line:453][INFO] TOXIC dataset pre-processed.
[2023-01-24 14:38:01][dataset.py][line:454][INFO] Sensitive Attribute is race, group is {'black': ['black'], 'white': ['white'], 'asian': ['asian'], 'other_race': ['latino', 'other_race_or_ethnicity']}
[2023-01-24 14:38:01][dataset.py][line:456][INFO] Accuracy bar is 0.4
[2023-01-24 14:38:04][dataset.py][line:388][INFO] TOXIC dataset Preprocessing ...
[2023-01-24 14:38:04][dataset.py][line:391][INFO] ## black
[2023-01-24 14:38:04][dataset.py][line:396][INFO] black examples num is: 15264
[2023-01-24 14:38:04][dataset.py][line:391][INFO] ## white
[2023-01-24 14:38:04][dataset.py][line:396][INFO] white examples num is: 26186
[2023-01-24 14:38:04][dataset.py][line:391][INFO] ## asian
[2023-01-24 14:38:04][dataset.py][line:396][INFO] asian examples num is: 3897
[2023-01-24 14:38:04][dataset.py][line:391][INFO] ## other_race
[2023-01-24 14:38:04][dataset.py][line:396][INFO] other_race examples num is: 1736
[2023-01-24 14:38:04][dataset.py][line:407][INFO] Task Dict: {0: 'others', 1: 'black', 2: 'white', 3: 'asian', 4: 'other_race'}
[2023-01-24 14:38:04][dataset.py][line:408][INFO] Grouped Info: 0.0    414812
2.0     20002
1.0      9145
3.0      3037
4.0      1004
Name: new_groups, dtype: int64
[2023-01-24 14:38:04][dataset.py][line:410][INFO] train: 
0.0    249032
2.0     12106
1.0      5503
3.0      1827
4.0       570
Name: new_groups, dtype: int64
[2023-01-24 14:38:04][dataset.py][line:410][INFO] test: 
0.0    124038
2.0      5772
1.0      2737
3.0       937
4.0       298
Name: new_groups, dtype: int64
[2023-01-24 14:38:04][dataset.py][line:410][INFO] val: 
0.0    41742
2.0     2124
1.0      905
3.0      273
4.0      136
Name: new_groups, dtype: int64
[2023-01-24 14:38:04][dataset.py][line:416][INFO] others toxicity is 0.12841261337443968
[2023-01-24 14:38:04][dataset.py][line:416][INFO] black toxicity is 0.32221311227962873
[2023-01-24 14:38:04][dataset.py][line:416][INFO] white toxicity is 0.2989624080578449
[2023-01-24 14:38:04][dataset.py][line:416][INFO] asian toxicity is 0.12338326578413271
[2023-01-24 14:38:04][dataset.py][line:416][INFO] other_race toxicity is 0.16404498980044838
[2023-01-24 14:38:05][dataset.py][line:431][INFO] TOXIC dataset Loaded.
[2023-01-24 14:38:05][dataset.py][line:75][INFO] SELECTED Data Info:
[2023-01-24 14:38:05][dataset.py][line:77][INFO] SELECTED Train Data: 269038 example with dim 768, y mean is 0.11881592934827051
[2023-01-24 14:38:05][dataset.py][line:82][INFO] SELECTED TRAIN [USER] are 5, maximum text per user is 249032, minimum text per user is 570, average text per user is 53807.6.
[2023-01-24 14:38:05][dataset.py][line:85][INFO] SELECTED TRAIN [LABEL] are [0 1], distribution is [237072  31966].
[2023-01-24 14:38:05][dataset.py][line:89][INFO] SELECTED Test Data: 133782 example with dim 768, y mean is 0.1188799689046359
[2023-01-24 14:38:05][dataset.py][line:94][INFO] SELECTED TEST [USER] are 5, maximum text per user is 124038, minimum text per user is 298, average text per user is 26756.4.
[2023-01-24 14:38:05][dataset.py][line:97][INFO] SELECTED TEST [LABEL] are [0 1], distribution is [117878  15904].
[2023-01-24 14:38:05][dataset.py][line:100][INFO] Added Information:
[2023-01-24 14:38:05][dataset.py][line:101][INFO] Train Data:
[2023-01-24 14:38:05][dataset.py][line:102][INFO] E(Y) = 0.11881592934827051
[2023-01-24 14:38:05][dataset.py][line:103][INFO] E(Y|a) = 0.19478722504258958
[2023-01-24 14:38:05][dataset.py][line:106][INFO] | E(Y|a)_train - E(Y|a)_train | mean = 0.08745465930035234
[2023-01-24 14:38:05][dataset.py][line:109][INFO] Test Data:
[2023-01-24 14:38:05][dataset.py][line:110][INFO] E(Y) = 0.1188799689046359
[2023-01-24 14:38:05][dataset.py][line:111][INFO] E(Y|a) = 0.18627254106720093
[2023-01-24 14:38:05][dataset.py][line:114][INFO] | E(Y|a)_test - E(Y|a)_test | mean = 0.08743982946252976
[2023-01-24 14:38:05][all_train.py][line:91][INFO] Namespace(config='EXPS/tadpole_template.yml', method='ours', dataset='toxic', sens_attrs='race', N_subtask=5, acc_bar=0.4, lower_rate=3, upper_rate=4, model_name='FcNet4', training_epoch=80, batch_size=50, max_inner=10, max_outer=5, lr_prior=0.001, lr_post=0.4, weight=0.4, divergence_type='W_Sqr', kappa_prior=0.01, kappa_post=0.001, log_var_init_mean=0.01, log_var_init_var=0.01, eps_std=0.08, n_MC=5, acc_bin=0.5, params={'n_bins': 5, 'interpolate_kind': 'linear'}, seed=0, use_wandb=False, wandb_username='YOURWANDBNAME', exp_name='toxic_race_example', train_inf_step=2, device=device(type='cpu'), log_var_init={'mean': 0.01, 'std': 0.01}, input_shape=768, output_dim=1)
[2023-01-24 14:38:05][fair_training.py][line:298][INFO] ===============Training Process=============
[2023-01-24 14:38:12][fair_training.py][line:316][INFO] The Initial overall accuracy is: 0.36475759070727004
